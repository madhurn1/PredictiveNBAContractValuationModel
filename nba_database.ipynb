{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Datasets and Create NBA Players Database\n",
    "\n",
    "In this notebook, we will load all of the datasets obtained from the internet through APIs, Kaggle, and other methods and clean the datasets for usage. We will use pandas and SQL to load and merge the datasets to create one master dataset for prediction.\n",
    "\n",
    "The database will feature NBA player stats, injury information, jersey sales information, team valuation information, and salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Define the path for the SQLite database\n",
    "sqlite_db_path = 'nba_players.db'\n",
    "\n",
    "# Remove existing SQLite DB if you want a fresh start (optional)\n",
    "if os.path.exists(sqlite_db_path):\n",
    "    os.remove(sqlite_db_path)\n",
    "\n",
    "# Create a connection string for SQLite\n",
    "connection_string = f'sqlite:///{sqlite_db_path}'\n",
    "\n",
    "# Create the SQLite engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Advanced Stats\n",
    "\n",
    "This dataset includes all of the advanced stats for all NBA players from 2019-2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "df = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA Advanced Stats(2019 - 2024).csv\")\n",
    "print(f\"Loaded NBA Advanced Stats with {df.shape[0]} rows.\")\n",
    "\n",
    "# Initial exploration of the data\n",
    "print(\"First 5 rows of the NBA Advanced Stats dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns)\n",
    "\n",
    "## DATA CLEANING\n",
    "\n",
    "# Drop rows with missing values in 'Player' or 'Season'\n",
    "df_cleaned = df.dropna(subset=['Player', 'Season'])\n",
    "print(f\"After dropping missing values: {df_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Remove duplicates: Keep the row with the greater 'MP' value\n",
    "df_cleaned = df_cleaned.sort_values(by='MP', ascending=False).drop_duplicates(subset=['Player', 'Season'], keep='first')\n",
    "print(f\"After removing duplicates: {df_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Create a unique player ID based on the combination of 'Season' and 'Player'\n",
    "df_cleaned['Unnamed: 0'] = df_cleaned['Season'].astype(str) + \"_\" + df_cleaned['Player']\n",
    "\n",
    "# Rename columns for consistency\n",
    "df_cleaned = df_cleaned.rename(columns={'Unnamed: 0': 'Player_ID'})\n",
    "df_cleaned = df_cleaned.rename(columns={'MP': 'Total MP'})\n",
    "\n",
    "# Sort by 'Player_ID' in ascending order and reset index\n",
    "df_cleaned = df_cleaned.sort_values(by='Player_ID').reset_index(drop=True)\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Import the DataFrame into the SQLite database\n",
    "df_cleaned.to_sql('nba_advanced_stats', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_advanced_stats' into SQLite database.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Per Game Playoff Stats\n",
    "\n",
    "This dataset has stats for all players from 2019-2024 who were part of playoff games for each year.\n",
    "\n",
    "The primary key is Player_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df2 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA Per Game PLAYOFF Stats(2019 - 2024).csv\")\n",
    "print(f\"Loaded NBA Per Game Playoff Stats with {df2.shape[0]} rows.\")\n",
    "\n",
    "# Initial exploration\n",
    "print(\"First 5 rows of the NBA Per Game Playoff Stats dataset:\")\n",
    "print(df2.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df2.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df2.describe())\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df2.columns)\n",
    "\n",
    "## DATA CLEANING\n",
    "\n",
    "# Drop rows with missing values in 'Player' or 'Season'\n",
    "df2_cleaned = df2.dropna(subset=['Player', 'Season'])\n",
    "print(f\"After dropping missing values: {df2_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Remove duplicates: Keep the first occurrence\n",
    "df2_cleaned = df2_cleaned.drop_duplicates(subset=['Player', 'Season'], keep='first')\n",
    "print(f\"After removing duplicates: {df2_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Create a unique player ID\n",
    "df2_cleaned['Unnamed: 0'] = df2_cleaned['Season'].astype(str) + \"_\" + df2_cleaned['Player']\n",
    "\n",
    "# Rename columns for consistency\n",
    "df2_cleaned = df2_cleaned.rename(columns={'Unnamed: 0': 'Player_ID'})\n",
    "df2_cleaned = df2_cleaned.rename(columns={'MP': 'MPG'})\n",
    "\n",
    "# Sort and reset index\n",
    "df2_cleaned = df2_cleaned.sort_values(by='Player_ID').reset_index(drop=True)\n",
    "print(df2_cleaned.head())\n",
    "\n",
    "# Import into SQLite\n",
    "df2_cleaned.to_sql('nba_playoff_stats', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_playoff_stats' into SQLite database.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Per Game Stats\n",
    "\n",
    "This dataset includes NBA statistics that are not in the advanced stats. The idea is to have the most comprehensive dataset to account for all performance factors dictating a contract. \n",
    "\n",
    "Once again, the primary key is Player_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df3 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA Per Game Stats(2019 - 2024).csv\")\n",
    "print(f\"Loaded NBA Per Game Stats with {df3.shape[0]} rows.\")\n",
    "\n",
    "# Initial exploration\n",
    "print(\"First 5 rows of the NBA Per Game Stats dataset:\")\n",
    "print(df3.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df3.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df3.describe())\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df3.isnull().sum())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df3.columns)\n",
    "\n",
    "## DATA CLEANING\n",
    "\n",
    "# Drop rows with missing values in 'Player' or 'Season'\n",
    "df3_cleaned = df3.dropna(subset=['Player', 'Season'])\n",
    "print(f\"After dropping missing values: {df3_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Remove duplicates: Keep the first occurrence\n",
    "df3_cleaned = df3_cleaned.drop_duplicates(subset=['Player', 'Season'], keep='first')\n",
    "print(f\"After removing duplicates: {df3_cleaned.shape[0]} rows.\")\n",
    "\n",
    "# Create a unique player ID\n",
    "df3_cleaned['Unnamed: 0'] = df3_cleaned['Season'].astype(str) + \"_\" + df3_cleaned['Player']\n",
    "\n",
    "# Rename columns for consistency\n",
    "df3_cleaned = df3_cleaned.rename(columns={'Unnamed: 0': 'Player_ID'})\n",
    "df3_cleaned = df3_cleaned.rename(columns={'MP': 'MPG'})\n",
    "\n",
    "# Sort and reset index\n",
    "df3_cleaned = df3_cleaned.sort_values(by='Player_ID').reset_index(drop=True)\n",
    "print(df3_cleaned.head())\n",
    "\n",
    "# Import into SQLite\n",
    "df3_cleaned.to_sql('nba_per_game_stats', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_per_game_stats' into SQLite database.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Player Injury Stats\n",
    "\n",
    "This dataset gave information about which players got injured, when they got injured, and what their injury was. The goal of cleaning and transforming this dataset was to provide the total injury days per player from 2019-2024 to show their availabilities during the season. We believe greater injury days should reduce the salary price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df4 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA Player Injury Stats(2019 - 2024).csv\")\n",
    "print(f\"Loaded NBA Player Injury Stats with {df4.shape[0]} rows.\")\n",
    "\n",
    "print(df4.columns)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df4['Date'] = pd.to_datetime(df4['Date'], errors='coerce')\n",
    "\n",
    "df4['Player'] = df4['Acquired'].fillna(df4['Relinquished']) # Identify the player name in each row\n",
    "\n",
    "# Store total injury days per player\n",
    "player_injury_days = {}\n",
    "\n",
    "for player in df4['Player'].unique():\n",
    "    # Filter rows for this player and sort by Date\n",
    "    player_data = df4[(df4['Relinquished'] == player) | (df4['Acquired'] == player)].sort_values(by='Date')\n",
    "\n",
    "    total_injury_days = 0\n",
    "    injury_start = None\n",
    "\n",
    "    for _, row in player_data.iterrows():\n",
    "        if row['Relinquished'] == player:\n",
    "            # Start a new injury period if no ongoing injury\n",
    "            if injury_start is None:\n",
    "                injury_start = row['Date']\n",
    "                print(f\"Start injury: {injury_start} for {player}\")\n",
    "        elif row['Acquired'] == player and injury_start is not None:\n",
    "            # End the current injury period\n",
    "            injury_end = row['Date']\n",
    "            print(f\"End injury: {injury_end} for {player}\")\n",
    "\n",
    "            # Calculate injury days\n",
    "            if injury_start < injury_end:\n",
    "                injury_days = (injury_end - injury_start).days\n",
    "                total_injury_days += injury_days\n",
    "                print(f\"Added {injury_days} days for {player}\")\n",
    "            else:\n",
    "                print(f\"Invalid period: {injury_start} -> {injury_end} for {player}\")\n",
    "\n",
    "            # Reset injury_start\n",
    "            injury_start = None\n",
    "\n",
    "    # Handle open-ended injuries\n",
    "    if injury_start is not None:\n",
    "        # End on the next July 6 or 2024-11-24 --> this either represents the end of the trade deadline or the latest day of data provided\n",
    "        year = injury_start.year\n",
    "        cutoff_date = datetime(year, 7, 6) if injury_start < datetime(year, 7, 6) else datetime(year + 1, 7, 6)\n",
    "        injury_end = min(cutoff_date, datetime(2024, 11, 24))\n",
    "\n",
    "        # Add only valid days\n",
    "        if injury_start < injury_end:\n",
    "            injury_days = (injury_end - injury_start).days\n",
    "            total_injury_days += injury_days\n",
    "            print(f\"Open-ended injury: Added {injury_days} days for {player}\")\n",
    "        else:\n",
    "            print(f\"Invalid open-ended period: {injury_start} -> {injury_end} for {player}\")\n",
    "\n",
    "    # Store total injury days for this player\n",
    "    player_injury_days[player] = total_injury_days\n",
    "    print(f\"Total days for {player}: {total_injury_days}\\n\")\n",
    "\n",
    "print(player_injury_days)\n",
    "\n",
    "## Clean the player names since there are unwanted words and characters in there\n",
    "\n",
    "import re\n",
    "\n",
    "# Clean the player names in the player_injury_days dictionary\n",
    "cleaned_player_injury_days = {}\n",
    "\n",
    "for player, injury_days in player_injury_days.items():\n",
    "    cleaned_name = re.sub(r'\\(.*?\\)', '', player)\n",
    "    # Keep only the name after the last '/'\n",
    "    cleaned_name = cleaned_name.split('/')[-1]\n",
    "    cleaned_player_injury_days[cleaned_name] = injury_days\n",
    "\n",
    "print(cleaned_player_injury_days)\n",
    "\n",
    "\n",
    "df4['Injury_Days'] = df4['Player'].map(cleaned_player_injury_days)\n",
    "\n",
    "print(df4.head())\n",
    "\n",
    "# Import into SQLite\n",
    "df4.to_sql('nba_injury_days', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_injury_days' into SQLite database.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Salaries\n",
    "\n",
    "We want to load this dataset to get all of the yearly salaries for each player in the dataset and add the salaries where the Player_ID matches. Therefore, there is appropriate information for analysis on a yearly basis for the entire NBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df5 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA Salaries(2019-2024).csv\")\n",
    "print(f\"Loaded NBA Salaries with {df5.shape[0]} rows.\")\n",
    "\n",
    "print(df5.head(20))\n",
    "\n",
    "# Transform\n",
    "df5_melted = pd.melt(\n",
    "    df5,\n",
    "    id_vars=[\"Unnamed: 0\", \"playerName\"],\n",
    "    var_name=\"Year\",\n",
    "    value_name=\"Salary\"\n",
    ")\n",
    "\n",
    "# We want the latest salary as this includes bonuses\n",
    "df5_melted[\"Year\"] = df5_melted[\"Year\"].str.replace(r\"\\(\\*\\)\", \"\", regex=True).str.strip()\n",
    "df5_melted[\"Year\"] = df5_melted[\"Year\"].str[:4]  \n",
    "\n",
    "df5_melted.head()\n",
    "df5_melted[\"Unnamed: 0\"] = df5_melted[\"Year\"] + \"_\" + df5_melted[\"playerName\"]\n",
    "\n",
    "df5_melted = df5_melted.rename(columns={'Unnamed: 0': 'Player_ID'})\n",
    "\n",
    "# Remove \"$\" and \",\" from Salary column and convert it to numeric\n",
    "df5_melted[\"Salary\"] = df5_melted[\"Salary\"].str.replace(\"[$,]\", \"\", regex=True).astype(float)\n",
    "\n",
    "# Sort by playerName, Year, and then keep the last value for duplicates\n",
    "df5_melted = df5_melted.sort_values(by=[\"playerName\", \"Year\"]).groupby([\"playerName\", \"Year\"]).nth(-1).reset_index()\n",
    "\n",
    "# Reorder the columns\n",
    "df5_melted = df5_melted[[\"Player_ID\", \"Year\", \"playerName\", \"Salary\"]]\n",
    "print(\"Cleaned NBA Salaries DataFrame:\")\n",
    "print(df5_melted.head(10))\n",
    "\n",
    "# Import into SQLite\n",
    "df5_melted.to_sql('nba_salaries', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_salaries' into SQLite database.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Team Valuations\n",
    "\n",
    "This dataset gives information about the values of each team. Some teams or worth more than others which is a factor in the contract sizes they are able to offer. Therefore, we need to take them into account and add that for each player where the Team code matches in each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df6 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/NBA_Team_Valuations_2024.csv\")\n",
    "print(\"Loaded NBA Team Valuations:\")\n",
    "print(df6)\n",
    "\n",
    "# Calculate mean and standard deviation for Valuation\n",
    "mean_valuation = df6[\"Valuation (in billions)\"].mean()\n",
    "std_valuation = df6[\"Valuation (in billions)\"].std()\n",
    "\n",
    "# Calculate z-scores\n",
    "df6[\"Z-Score\"] = (df6[\"Valuation (in billions)\"] - mean_valuation) / std_valuation\n",
    "\n",
    "# Apply scaling factor and set bounds for the multipliers as it should not affect the contract too much\n",
    "# This helps for standardization\n",
    "scaling_factor = 0.1  \n",
    "df6[\"Valuation_Multiplier\"] = 1 + (scaling_factor * df6[\"Z-Score\"])\n",
    "df6[\"Valuation_Multiplier\"] = df6[\"Valuation_Multiplier\"].clip(lower=0.8, upper=1.2)\n",
    "print(df6.head())\n",
    "\n",
    "# Import into SQLite\n",
    "df6.to_sql('nba_team_valuations', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_team_valuations' into SQLite database.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Clean NBA Jersey Sales\n",
    "\n",
    "This gives information of which players were in the Top 15 for Jersey Sales. This contributes to their contracts as a bigger brand attracts more attention to the team. This increases sales and increases the value of the team. Therefore, players who have a lot of jersey sales receive larger contracts. \n",
    "\n",
    "This only applies to players for 2023 as this is the latest branding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df7 = pd.read_csv(r\"C:/Users/mdani/OneDrive/Desktop/nba_players/Top_NBA_Jersey_Sales.csv\")\n",
    "print(\"Loaded Top NBA Jersey Sales:\")\n",
    "print(df7.head())\n",
    "\n",
    "df_sub = df7[[\"2023-2024\", \"Multiplier\"]].copy()\n",
    "df_sub[\"Player_ID\"] = \"2023_\" + df_sub[\"2023-2024\"]\n",
    "\n",
    "# Rename columns\n",
    "df_sub = df_sub.rename(columns={\"2023-2024\": \"Player_Name\", \"Multiplier\": \"Jerseys Multiplier\"})\n",
    "print(df_sub.head())\n",
    "\n",
    "# Import into SQLite\n",
    "df_sub.to_sql('nba_jersey_sales', engine, if_exists='replace', index=False)\n",
    "print(\"Imported 'nba_jersey_sales' into SQLite database.\\n\")\n",
    "\n",
    "print(\"All tables have been successfully imported into the SQLite database 'nba_players.db'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Aggregate Table with ONLY Active Players\n",
    "\n",
    "Here, we will use SQL to create an aggregate table that will house all information for each player per season. We will populate the full stats table using the primary keys of each individual dataset, and we will use SQL statements to accomplish this. We\n",
    "\n",
    "Then, we will use an SQL statement to get a subtable of players that excludes inactive/retired players and only has players that are still in the NBA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "connection = sqlite3.connect('nba_players.db')  \n",
    "cursor = connection.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nba_full_stats (\n",
    "    Player_ID INTEGER,\n",
    "    Player TEXT,\n",
    "    Team TEXT,\n",
    "    Pos TEXT,\n",
    "    Age INTEGER,\n",
    "    G INTEGER,\n",
    "    GS INTEGER,\n",
    "    MPG REAL,\n",
    "    FG REAL,\n",
    "    FGA REAL,\n",
    "    \"3P\" REAL,\n",
    "    \"3PA\" REAL,\n",
    "    \"3P%\" REAL,\n",
    "    \"2P\" REAL,\n",
    "    \"2PA\" REAL,\n",
    "    \"2P%\" REAL,\n",
    "    eFG_percent REAL,\n",
    "    FT REAL,\n",
    "    FTA REAL,\n",
    "    \"FT%\" REAL,\n",
    "    ORB REAL,\n",
    "    DRB REAL,\n",
    "    TRB REAL,\n",
    "    AST REAL,\n",
    "    STL REAL,\n",
    "    BLK REAL,\n",
    "    TOV REAL,\n",
    "    PF REAL,\n",
    "    PTS REAL,\n",
    "    Total_MP REAL,\n",
    "    PER REAL,\n",
    "    TS_percent REAL,\n",
    "    \"3PAr\" REAL,\n",
    "    \"FTr\" REAL,\n",
    "    ORB_percent REAL,\n",
    "    DRB_percent REAL,\n",
    "    TRB_percent REAL,\n",
    "    AST_percent REAL,\n",
    "    STL_percent REAL,\n",
    "    BLK_percent REAL,\n",
    "    TOV_percent REAL,\n",
    "    USG_percent REAL,\n",
    "    OWS REAL,\n",
    "    DWS REAL,\n",
    "    WS REAL,\n",
    "    WS_per_48 REAL,\n",
    "    OBPM REAL,\n",
    "    DBPM REAL,\n",
    "    BPM REAL,\n",
    "    VORP REAL,\n",
    "    p_G TEXT,\n",
    "    p_GS TEXT,\n",
    "    p_MPG TEXT,\n",
    "    p_FG TEXT,\n",
    "    p_FGA TEXT,\n",
    "    p_FG_percent TEXT,\n",
    "    p_3P TEXT,\n",
    "    p_3PA TEXT,\n",
    "    p_3P_percent TEXT,\n",
    "    p_2P TEXT,\n",
    "    p_2PA TEXT,\n",
    "    p_2P_percent TEXT,\n",
    "    p_eFG_percent TEXT,\n",
    "    p_FT TEXT,\n",
    "    p_FTA TEXT,\n",
    "    p_FT_percent TEXT,\n",
    "    p_ORB TEXT,\n",
    "    p_DRB TEXT,\n",
    "    p_TRB TEXT,\n",
    "    p_AST TEXT,\n",
    "    p_STL TEXT,\n",
    "    p_BLK TEXT,\n",
    "    p_TOV TEXT,\n",
    "    p_PF TEXT,\n",
    "    p_PTS TEXT,\n",
    "    Jerseys_Multiplier REAL,\n",
    "    Salary REAL,\n",
    "    Injury_Days INTEGER,\n",
    "    Valuation_Multiplier REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "import sqlite3\n",
    "connection = sqlite3.connect('nba_players.db')  \n",
    "cursor = connection.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO nba_full_stats (\n",
    "    Player_ID, Player, Team, Pos, Age, G, GS, Total_MP, PER, TS_percent, \n",
    "    \"3PAr\", \"FTr\", ORB_percent, DRB_percent, TRB_percent, AST_percent, STL_percent, \n",
    "    BLK_percent, TOV_percent, USG_percent, OWS, DWS, WS, WS_per_48, OBPM, DBPM, \n",
    "    BPM, VORP\n",
    ")\n",
    "SELECT \n",
    "    Player_ID, Player, Team, Pos, Age, G, GS, \n",
    "    \"Total MP\", PER, \"TS%\", \"3PAr\", \"FTr\", \"ORB%\", \"DRB%\", \n",
    "    \"TRB%\", \"AST%\", \"STL%\", \"BLK%\", \"TOV%\", \"USG%\", OWS, \n",
    "    DWS, WS, \"WS/48\", OBPM, DBPM, BPM, VORP\n",
    "FROM nba_advanced_stats;\n",
    "\"\"\"\n",
    "cursor.execute(insert_query)\n",
    "connection.commit()\n",
    "\n",
    "update_query_game_stat = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET \n",
    "    MPG = (SELECT MPG FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    FG = (SELECT FG FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    FGA = (SELECT FGA FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"3P\" = (SELECT \"3P\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"3PA\" = (SELECT \"3PA\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"3P%\" = (SELECT \"3P%\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"2P\" = (SELECT \"2P\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"2PA\" = (SELECT \"2PA\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"2P%\" = (SELECT \"2P%\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    eFG_percent = (SELECT \"eFG%\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    FT = (SELECT FT FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    FTA = (SELECT FTA FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    \"FT%\" = (SELECT \"FT%\" FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    ORB = (SELECT ORB FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    DRB = (SELECT DRB FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    TRB = (SELECT TRB FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    AST = (SELECT AST FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    STL = (SELECT STL FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    BLK = (SELECT BLK FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    TOV = (SELECT TOV FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    PF = (SELECT PF FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    PTS = (SELECT PTS FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID)\n",
    "WHERE EXISTS (SELECT 1 FROM nba_per_game_stats WHERE nba_per_game_stats.Player_ID = nba_full_stats.Player_ID);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_query_game_stat)\n",
    "connection.commit()\n",
    "\n",
    "update_playoff_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET \n",
    "    p_G = (SELECT G FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_GS = (SELECT GS FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_MPG = (SELECT MPG FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FG = (SELECT FG FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FGA = (SELECT FGA FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FG_percent = (SELECT \"FG%\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_3P = (SELECT \"3P\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_3PA = (SELECT \"3PA\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_3P_percent = (SELECT \"3P%\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_2P = (SELECT \"2P\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_2PA = (SELECT \"2PA\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_2P_percent = (SELECT \"2P%\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_eFG_percent = (SELECT \"eFG%\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FT = (SELECT FT FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FTA = (SELECT FTA FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_FT_percent = (SELECT \"FT%\" FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_ORB = (SELECT ORB FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_DRB = (SELECT DRB FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_TRB = (SELECT TRB FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_AST = (SELECT AST FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_STL = (SELECT STL FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_BLK = (SELECT BLK FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_TOV = (SELECT TOV FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_PF = (SELECT PF FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID),\n",
    "    p_PTS = (SELECT PTS FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID)\n",
    "WHERE EXISTS (SELECT 1 FROM nba_playoff_stats WHERE nba_playoff_stats.Player_ID = nba_full_stats.Player_ID);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_playoff_query)\n",
    "connection.commit()\n",
    "\n",
    "update_jerseys_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET Jerseys_Multiplier = (\n",
    "    SELECT \"Jerseys Multiplier\"\n",
    "    FROM nba_jersey_sales\n",
    "    WHERE nba_jersey_sales.Player_ID = nba_full_stats.Player_ID\n",
    ")\n",
    "WHERE EXISTS (\n",
    "    SELECT 1\n",
    "    FROM nba_jersey_sales\n",
    "    WHERE nba_jersey_sales.Player_ID = nba_full_stats.Player_ID\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_jerseys_query)\n",
    "connection.commit()\n",
    "\n",
    "update_salary_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET Salary = (\n",
    "    SELECT Salary\n",
    "    FROM nba_salaries\n",
    "    WHERE nba_salaries.Player_ID = nba_full_stats.Player_ID\n",
    ")\n",
    "WHERE EXISTS (\n",
    "    SELECT 1\n",
    "    FROM nba_salaries\n",
    "    WHERE nba_salaries.Player_ID = nba_full_stats.Player_ID\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_salary_query)\n",
    "connection.commit()\n",
    "\n",
    "update_injury_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET Injury_Days = (\n",
    "    SELECT (Injury_Days)\n",
    "    FROM nba_injury_days\n",
    "    WHERE LOWER(TRIM(nba_injury_days.Player)) = LOWER(TRIM(nba_full_stats.Player))\n",
    ")\n",
    "WHERE EXISTS (\n",
    "    SELECT 1\n",
    "    FROM nba_injury_days\n",
    "    WHERE LOWER(TRIM(nba_injury_days.Player)) = LOWER(TRIM(nba_full_stats.Player))\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_injury_query)\n",
    "connection.commit()\n",
    "\n",
    "update_valuation_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET Valuation_Multiplier = (\n",
    "    SELECT Valuation_Multiplier\n",
    "    FROM nba_team_valuations\n",
    "    WHERE LOWER(TRIM(nba_team_valuations.Team)) = LOWER(TRIM(nba_full_stats.Team))\n",
    ")\n",
    "WHERE EXISTS (\n",
    "    SELECT 1\n",
    "    FROM nba_team_valuations\n",
    "    WHERE LOWER(TRIM(nba_team_valuations.Team)) = LOWER(TRIM(nba_full_stats.Team))\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_valuation_query)\n",
    "connection.commit()\n",
    "\n",
    "# add column for season to be able to explore the data over different time periods\n",
    "cursor.execute(\"ALTER TABLE nba_full_stats ADD COLUMN season TEXT\")\n",
    "connection.commit()\n",
    "\n",
    "update_query = \"\"\"\n",
    "UPDATE nba_full_stats\n",
    "SET season = (\n",
    "    SELECT season\n",
    "    FROM nba_advanced_stats\n",
    "    WHERE nba_full_stats.Player_ID = nba_advanced_stats.Player_ID\n",
    ")\n",
    "WHERE Player_ID IN (SELECT Player_ID FROM nba_advanced_stats)\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_query)\n",
    "connection.commit()\n",
    "\n",
    "## Create subtable for only active players\n",
    "connection = sqlite3.connect('nba_players.db')  \n",
    "cursor = connection.cursor()\n",
    "\n",
    "create_subtable_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nba_full_stats_2024 AS\n",
    "SELECT fs.*\n",
    "FROM nba_full_stats fs\n",
    "WHERE LOWER(TRIM(fs.Player)) IN (\n",
    "    SELECT DISTINCT LOWER(TRIM(Player))\n",
    "    FROM nba_advanced_stats\n",
    "    WHERE Season = 2024\n",
    ")\n",
    "ORDER BY fs.Player, fs.season;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_subtable_query)\n",
    "connection.commit()\n",
    "\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
